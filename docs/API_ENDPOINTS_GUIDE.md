# API ç«¯ç‚¹é…ç½®æŒ‡å—

æœ¬æŒ‡å—è¯´æ˜å¦‚ä½•é…ç½®OpenAIå…¼å®¹çš„APIæä¾›å•†ï¼ŒåŒ…æ‹¬è·å–APIå¯†é’¥å’Œè®¾ç½®è‡ªå®šä¹‰URLçš„æ­¥éª¤ã€‚

## ç›®å½•
1. [OpenAI](#openai)
2. [DeepSeek](#deepseek)
3. [æœ¬åœ°æœåŠ¡å™¨](#æœ¬åœ°æœåŠ¡å™¨)
4. [å…¶ä»–å…¼å®¹æä¾›å•†](#å…¶ä»–å…¼å®¹æä¾›å•†)
5. [é…ç½®æ–¹æ³•](#é…ç½®æ–¹æ³•)
6. [Condaç¯å¢ƒç®¡ç†](#condaç¯å¢ƒç®¡ç†)

---

## OpenAI

### å®˜æ–¹ç½‘ç«™
ğŸŒ https://openai.com

### è·å–APIå¯†é’¥

1. **è®¿é—® OpenAI Platform**
   - ç™»å½•: https://platform.openai.com/login
   - æ²¡æœ‰è´¦æˆ·ï¼Ÿæ³¨å†Œ: https://platform.openai.com/signup

2. **è·å–APIå¯†é’¥**
   - è¿›å…¥ "API keys" é¡µé¢: https://platform.openai.com/account/api-keys
   - ç‚¹å‡» "Create new secret key"
   - å¤åˆ¶å¯†é’¥å¹¶ä¿å­˜ï¼ˆåªä¼šæ˜¾ç¤ºä¸€æ¬¡ï¼‰

### å¯ç”¨æ¨¡å‹
- `gpt-4` - æœ€å¼ºå¤§çš„æ¨¡å‹
- `gpt-4-turbo` - æ›´å¿«çš„GPT-4å˜ä½“
- `gpt-3.5-turbo` - æœ€ç»æµçš„é€‰æ‹©ï¼ˆæ¨èï¼‰
- `gpt-3.5-turbo-16k` - æ›´å¤§çš„ä¸Šä¸‹æ–‡çª—å£

### APIç«¯ç‚¹
```
Base URL: https://api.openai.com/v1
Chat Completion: https://api.openai.com/v1/chat/completions
```

### é…ç½®ç¤ºä¾‹

#### .env æ–‡ä»¶
```bash
OPENAI_API_KEY=sk-your-api-key-here
```

#### config/config.yaml
```yaml
llm:
  openai:
    enabled: true
    api_key: ${OPENAI_API_KEY}
    model: gpt-3.5-turbo
    base_url: https://api.openai.com/v1
    temperature: 0.7
    max_tokens: 2000
```

### æˆæœ¬
- GPT-3.5-turbo: $0.0005/1K tokens (input), $0.0015/1K tokens (output)
- GPT-4: $0.03/1K tokens (input), $0.06/1K tokens (output)

### æ–‡æ¡£
- å®˜æ–¹æ–‡æ¡£: https://platform.openai.com/docs
- APIå‚è€ƒ: https://platform.openai.com/docs/api-reference

---

## DeepSeek

### å®˜æ–¹ç½‘ç«™
ğŸŒ https://www.deepseek.com

### è·å–APIå¯†é’¥

1. **è®¿é—® DeepSeek**
   - å®˜ç½‘: https://www.deepseek.com
   - æ–‡æ¡£: https://github.com/deepseek-ai
   - APIå¹³å°: https://platform.deepseek.com

2. **åˆ›å»ºAPIå¯†é’¥**
   - æ³¨å†Œè´¦æˆ·
   - è¿›å…¥æ§åˆ¶é¢æ¿
   - åˆ›å»ºæ–°çš„APIå¯†é’¥
   - å¤åˆ¶ä¿å­˜

### å¯ç”¨æ¨¡å‹
- `deepseek-chat` - ä¸»è¦å¯¹è¯æ¨¡å‹
- `deepseek-coder` - ä»£ç ä¸“ç”¨æ¨¡å‹
- å…¶ä»–å˜ä½“è¯·æŸ¥é˜…æœ€æ–°æ–‡æ¡£

### APIç«¯ç‚¹
```
Base URL: https://api.deepseek.com
Chat Completion: https://api.deepseek.com/chat/completions
```

### é…ç½®ç¤ºä¾‹

#### .env æ–‡ä»¶
```bash
DEEPSEEK_API_KEY=your-deepseek-api-key-here
```

#### config/config.yaml
```yaml
llm:
  openai_compatible:
    deepseek:
      enabled: true
      api_key: ${DEEPSEEK_API_KEY}
      model: deepseek-chat
      base_url: https://api.deepseek.com
      temperature: 0.7
      max_tokens: 2000
      provider_name: "DeepSeek"
```

### æˆæœ¬
- æ£€æŸ¥å®˜æ–¹å®šä»·: https://www.deepseek.com/pricing

### ä½¿ç”¨ç¤ºä¾‹
```python
from src.llm import LLMManager
from src.utils import get_config

config = get_config()
llm = LLMManager(config=config)

# DeepSeekä¼šè‡ªåŠ¨åˆå§‹åŒ–
response = await llm.complete(
    messages=[{"role": "user", "content": "Hello"}],
    preferred_provider="deepseek"
)
```

### æ–‡æ¡£
- GitHub: https://github.com/deepseek-ai
- APIæ–‡æ¡£: https://github.com/deepseek-ai/DeepSeek-API

---

## æœ¬åœ°æœåŠ¡å™¨

å¦‚æœä½¿ç”¨æœ¬åœ°OpenAIå…¼å®¹æœåŠ¡å™¨ï¼ˆå¦‚LM Studioã€vLLMç­‰ï¼‰ï¼Œå¯ä»¥ç›´æ¥æŒ‡å‘æœ¬åœ°URLã€‚

### LM Studio

ğŸŒ https://lmstudio.ai

#### å®‰è£…å’Œè¿è¡Œ
1. ä¸‹è½½ LM Studio: https://lmstudio.ai
2. å®‰è£…å¹¶å¯åŠ¨
3. åŠ è½½æ¨¡å‹
4. å¯åŠ¨æœ¬åœ°æœåŠ¡å™¨ï¼ˆé€šå¸¸åœ¨ `http://localhost:8000`ï¼‰

#### å¯ç”¨æ¨¡å‹
- æ”¯æŒHugging Faceä¸Šçš„å¤§å¤šæ•°æ¨¡å‹
- çƒ­é—¨é€‰æ‹©: Llama 2, Mistral, Neural Chatç­‰

#### APIç«¯ç‚¹
```
Base URL: http://localhost:8000/v1
Chat Completion: http://localhost:8000/v1/chat/completions
```

#### é…ç½®ç¤ºä¾‹

##### config/config.yaml
```yaml
llm:
  openai_compatible:
    local_compatible:
      enabled: true
      api_key: "local-key"  # æœ¬åœ°æ— éœ€çœŸå®å¯†é’¥
      model: llama-2        # ä½¿ç”¨ä½ åŠ è½½çš„æ¨¡å‹
      base_url: http://localhost:8000/v1
      temperature: 0.7
      max_tokens: 2000
      provider_name: "LocalOpenAI"
```

#### ä½¿ç”¨ç¤ºä¾‹
```python
response = await llm.complete(
    messages=[...],
    preferred_provider="local_compatible"
)
```

### vLLM

ğŸŒ https://github.com/lm-sys/vLLM

#### å®‰è£…å’Œè¿è¡Œ
```bash
# å®‰è£… vLLM
pip install vllm

# å¯åŠ¨æœåŠ¡å™¨
python -m vllm.entrypoints.openai.api_server \
  --model meta-llama/Llama-2-7b-hf \
  --port 8000
```

#### APIç«¯ç‚¹
```
Base URL: http://localhost:8000/v1
```

#### é…ç½®ç¤ºä¾‹
åŒLM Studioï¼Œåªéœ€æ”¹å˜base_urlæŒ‡å‘vLLMå®ä¾‹

### å…¶ä»–æœ¬åœ°é€‰é¡¹
- **Ollama** - å·²å†…ç½®æ”¯æŒï¼ˆå‚è§ `Ollama Local Model Configuration`ï¼‰
- **Text Generation WebUI** - æ”¯æŒOpenAIå…¼å®¹API
- **LocalAI** - æœ¬åœ°LLMæ¨ç†å¼•æ“

---

## å…¶ä»–å…¼å®¹æä¾›å•†

### Together AI

ğŸŒ https://www.together.ai

#### è·å–APIå¯†é’¥
1. æ³¨å†Œ: https://www.together.ai
2. è·å–APIå¯†é’¥: https://www.together.ai/settings/api-keys

#### APIç«¯ç‚¹
```
Base URL: https://api.together.xyz/v1
```

#### é…ç½®ç¤ºä¾‹
```yaml
llm:
  openai_compatible:
    together_ai:
      enabled: true
      api_key: ${TOGETHER_API_KEY}
      model: meta-llama/Llama-2-7b-hf
      base_url: https://api.together.xyz/v1
      provider_name: "TogetherAI"
```

### Replicate

ğŸŒ https://replicate.com

#### è·å–APIå¯†é’¥
1. æ³¨å†Œ: https://replicate.com/signin
2. API Token: https://replicate.com/account/api-tokens

#### APIç«¯ç‚¹
```
Base URL: https://api.replicate.com/v1
```

### Azure OpenAI

å¦‚æœä½¿ç”¨ Azure æä¾›çš„ OpenAI æœåŠ¡ï¼š

#### APIç«¯ç‚¹æ ¼å¼
```
Base URL: https://{resource-name}.openai.azure.com/v1
```

#### é…ç½®ç¤ºä¾‹
```yaml
llm:
  openai:
    enabled: true
    api_key: ${AZURE_OPENAI_KEY}
    model: gpt-35-turbo
    base_url: https://your-resource.openai.azure.com/v1
```

---

## é…ç½®æ–¹æ³•

### æ–¹æ³•1: ä½¿ç”¨ .env æ–‡ä»¶

1. **åˆ›å»º .env æ–‡ä»¶**
   ```bash
   cp .env.example .env
   ```

2. **æ·»åŠ APIå¯†é’¥**
   ```bash
   # .env
   OPENAI_API_KEY=sk-your-key
   DEEPSEEK_API_KEY=your-deepseek-key
   TOGETHER_API_KEY=your-together-key
   ```

3. **éªŒè¯é…ç½®**
   ```bash
   python -m src.main info
   ```

### æ–¹æ³•2: ç¼–è¾‘ config/config.yaml

ç›´æ¥ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„ `base_url` å’Œ `api_key`ï¼š

```yaml
llm:
  openai:
    enabled: true
    api_key: sk-your-key
    base_url: https://api.openai.com/v1  # ä¿®æ”¹è¿™é‡Œ
    model: gpt-3.5-turbo
```

### æ–¹æ³•3: é€šè¿‡Pythonä»£ç 

```python
from src.llm import OpenAIClient, LLMManager

# ç›´æ¥åˆ›å»ºå®¢æˆ·ç«¯
client = OpenAIClient(
    api_key="your-api-key",
    model="gpt-3.5-turbo",
    base_url="https://your-custom-endpoint.com/v1",
    provider_name="CustomProvider"
)

# æˆ–é€šè¿‡LLMManager
llm = LLMManager()
llm.add_provider("custom", client)
```

---

## ä¼˜å…ˆçº§å’ŒFallback

ç³»ç»Ÿä¼šæŒ‰ä»¥ä¸‹ä¼˜å…ˆçº§å°è¯•LLMæä¾›å•†ï¼š

1. **preferred_provider** - å¦‚æœæŒ‡å®š
2. **_primary_provider** - ç¬¬ä¸€ä¸ªé…ç½®çš„æä¾›å•†
3. **å…¶ä»–é…ç½®çš„æä¾›å•†** - æŒ‰é…ç½®é¡ºåº
4. **å¦‚æœå…¨éƒ¨å¤±è´¥** - æŠ›å‡ºé”™è¯¯

### è‡ªåŠ¨Fallbackç¤ºä¾‹
```python
# å¦‚æœ OpenAI ä¸å¯ç”¨ï¼Œä¼šè‡ªåŠ¨å°è¯• DeepSeek
response = await llm.complete(messages=[...])
```

---

## Conda ç¯å¢ƒç®¡ç†

å¦‚æ‚¨æåˆ°çš„ï¼Œä½¿ç”¨ Conda æ¥ç®¡ç†ç¯å¢ƒæ˜¯ä¸€ä¸ªæœ€ä½³å®è·µã€‚

### åˆ›å»ºCondaç¯å¢ƒ

```bash
# åˆ›å»ºæ–°ç¯å¢ƒ
conda create -n ai-search python=3.11

# æ¿€æ´»ç¯å¢ƒ
conda activate ai-search

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### ç¯å¢ƒç®¡ç†æœ€ä½³å®è·µ

```bash
# æŸ¥çœ‹æ‰€æœ‰ç¯å¢ƒ
conda env list

# åˆ›å»ºå¸¦ç‰¹å®šPythonç‰ˆæœ¬çš„ç¯å¢ƒ
conda create -n ai-search python=3.11 pip

# æ¿€æ´»ç¯å¢ƒ
conda activate ai-search

# åœ¨ç¯å¢ƒä¸­å®‰è£…åŒ…
pip install -r requirements.txt

# å¯¼å‡ºç¯å¢ƒé…ç½®
conda env export > environment.yml

# ä»é…ç½®æ–‡ä»¶é‡å»ºç¯å¢ƒ
conda env create -f environment.yml

# ç§»é™¤ç¯å¢ƒ
conda env remove -n ai-search

# æ›´æ–°æ‰€æœ‰åŒ…
conda update --all
```

### åˆ›å»º environment.yml æ–‡ä»¶

```yaml
# environment.yml
name: ai-search
channels:
  - defaults
  - conda-forge
dependencies:
  - python=3.11
  - pip
  - pip:
    - -r requirements.txt
```

### æ¨èçš„å·¥ä½œæµ

```bash
# 1. å…‹éš†é¡¹ç›®
git clone <your-repo>
cd ai_search

# 2. åˆ›å»ºCondaç¯å¢ƒ
conda create -n ai-search python=3.11

# 3. æ¿€æ´»ç¯å¢ƒ
conda activate ai-search

# 4. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 5. é…ç½®APIå¯†é’¥
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶

# 6. éªŒè¯è®¾ç½®
python -m src.main info

# 7. å¼€å§‹ä½¿ç”¨
python -m src.main ask "Hello" --auto
```

---

## å¸¸è§é—®é¢˜

### Q1: å¦‚ä½•åˆ‡æ¢APIæä¾›å•†ï¼Ÿ

```python
# åœ¨å‘½ä»¤è¡Œä¸­æŒ‡å®š
python -m src.main ask "é—®é¢˜" --auto

# åœ¨Pythonä¸­æŒ‡å®š
response = await llm.complete(
    messages=[...],
    preferred_provider="deepseek"  # æˆ– "local_compatible"
)
```

### Q2: è‡ªå®šä¹‰URLä¸å·¥ä½œæ€ä¹ˆåŠï¼Ÿ

æ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
1. URLæ ¼å¼æ˜¯å¦æ­£ç¡®ï¼ˆåº”åŒ…å« `/v1`ï¼‰
2. APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ
3. æœåŠ¡å™¨æ˜¯å¦åœ¨çº¿ä¸”å¯è®¿é—®
4. é˜²ç«å¢™/ä»£ç†è®¾ç½®æ˜¯å¦å…è®¸è®¿é—®
5. æŸ¥çœ‹è¯¦ç»†æ—¥å¿—: `python -m src.main ask "test" --verbose`

### Q3: å¦‚ä½•åœ¨å¤šä¸ªLLMä¹‹é—´åˆ‡æ¢ï¼Ÿ

```python
# config.yaml ä¸­å¯ç”¨å¤šä¸ªæä¾›å•†
llm:
  openai:
    enabled: true
  deepseek:
    enabled: true
  local_compatible:
    enabled: true

# ç„¶ååœ¨è¿è¡Œæ—¶é€‰æ‹©
response = await llm.complete(
    messages=[...],
    preferred_provider="deepseek"
)
```

### Q4: æœ¬åœ°æœåŠ¡å™¨éœ€è¦ç½‘ç»œè¿æ¥å—ï¼Ÿ

ä¸éœ€è¦ã€‚æœ¬åœ°æœåŠ¡å™¨ï¼ˆå¦‚LM Studioã€vLLMï¼‰è¿è¡Œåœ¨ `localhost`ï¼Œå®Œå…¨ç¦»çº¿å·¥ä½œã€‚

### Q5: å¦‚ä½•æµ‹è¯•æ–°çš„APIç«¯ç‚¹ï¼Ÿ

```bash
# å¯ç”¨è¯¦ç»†æ¨¡å¼
python -m src.main ask "test" --verbose

# æˆ–ç¼–å†™æµ‹è¯•è„šæœ¬
python << 'EOF'
import asyncio
from src.llm import OpenAIClient

async def test():
    client = OpenAIClient(
        api_key="your-key",
        base_url="https://your-endpoint/v1",
        provider_name="Test"
    )
    if await client.is_available():
        response = await client.complete([
            {"role": "user", "content": "Hello"}
        ])
        print(response)

asyncio.run(test())
EOF
```

---

## å®‰å…¨æç¤º

1. **ä¸è¦ç¡¬ç¼–ç APIå¯†é’¥**
   - âŒ é”™è¯¯: `api_key: "sk-xxx"`
   - âœ… æ­£ç¡®: `api_key: ${OPENAI_API_KEY}`

2. **ä½¿ç”¨ .env æ–‡ä»¶**
   - å°† `.env` æ·»åŠ åˆ° `.gitignore`
   - åªæäº¤ `.env.example`

3. **ç¯å¢ƒå˜é‡éš”ç¦»**
   - ä¸ºä¸åŒçš„APIä½¿ç”¨ä¸åŒçš„ç¯å¢ƒå˜é‡
   - å®šæœŸè½®æ¢APIå¯†é’¥

4. **Condaç¯å¢ƒéš”ç¦»**
   - ä¸ºä¸åŒé¡¹ç›®ä½¿ç”¨ä¸åŒçš„Condaç¯å¢ƒ
   - é¿å…å…¨å±€å®‰è£…ä¾èµ–

---

## è”ç³»å’Œæ”¯æŒ

- OpenAI: https://help.openai.com
- DeepSeek: https://github.com/deepseek-ai/DeepSeek-API/issues
- æœ¬åœ°å·¥å…·é—®é¢˜: æŸ¥çœ‹ç›¸åº”é¡¹ç›®çš„GitHub issues

---

**æ›´æ–°äº**: 2024å¹´10æœˆ20æ—¥

ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼ğŸš€
