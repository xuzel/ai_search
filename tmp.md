## 系统设计概述

本系统采用分层模块化架构，以智能路由为核心决策机制。该架构通过四类专用 Agent 处理不同类型的查询任务，构建统一的任务执行管道。各类查询首先经过智能分类模块进行任务类型识别，随后被分配至相应的 Agent 执行。该设计兼顾灵活性与效率：简单查询由领域工具直接处理以降低延迟，复杂查询则通过多步处理流程、并行工具调用和结果综合获得高质量输出。

用户查询输入后由混合路由器进行分类处理，该路由器采用两层决策策略。第一层通过关键词匹配实现快速分类，当置信度达到阈值时直接返回路由决策；当置信度不足时执行第二层的语言模型分类以获取精确的任务类型判断。确定任务类型后，对应 Agent 启动执行流程，协调工具调用与模型推理。所有执行结果经过聚合后进入数据库持久化，最后通过流式传输返回用户。该架构通过代码执行隔离机制保证安全性，通过多语言模型提供商的自适应选择保证可靠性，实现了查询处理的最优路径规划。

## 技术栈

**后端框架** 本系统采用 FastAPI 作为 Web 应用框架，其异步特性支持高并发请求处理。Typer 框架提供命令行接口功能，aiohttp 库实现异步 HTTP 通信，共同构成了系统的输入输出层。

**数据库与向量存储** 对话历史数据采用 SQLite 结合 aiosqlite 异步驱动进行存储，实现轻量级的本地数据持久化。文档问答任务所需的向量存储采用 ChromaDB，支持语义向量检索与高效相似度计算。

**核心语言模型与 API** 系统集成多个语言模型提供商以实现自适应选择。Aliyun Qwen 系列模型作为主力选择，OpenAI GPT 系列作为备用方案，DeepSeek 和 Ollama 提供额外的可选性。该多提供商架构通过自动故障转移机制保证服务的连续性和可靠性。

**关键依赖库** 如表1所示，系统依赖的关键库涵盖网页搜索、文本处理、向量化、文档解析、多模态分析和领域数据获取等多个方面。

| 功能模块 | 核心库 | 版本 | 用途 |
|---------|--------|------|------|
| **网页搜索与抽取** | google-search-results | 2.4.2 | SerpAPI 搜索集成 |
| | trafilatura | 1.6.0 | 网页正文提取 |
| | beautifulsoup4 | 4.12.2 | HTML 解析 |
| **向量化与重排** | sentence-transformers | 2.3.1 | 文本向量化 |
| | chromadb | 0.4.22 | 向量数据库 |
| | transformers | 4.37.2 | BGE 重排模型 |
| **代码执行隔离** | Docker | - | 容器隔离 |
| | ast | - | 代码安全验证 |
| **文档处理** | pymupdf | 1.23.8 | PDF 解析 |
| | pdfplumber | 0.10.3 | PDF 表格提取 |
| | python-docx | 1.1.0 | Word 文档解析 |
| **数据处理** | pandas | 1.5.0 | 数据操作 |
| | numpy | 1.24.0 | 数值计算 |
| **多模态分析** | paddleocr | 2.10.0 | 文字识别 |
| | paddlepaddle | 3.2.1 | OCR 计算后端 |
| | google-generativeai | 0.8.5 | Gemini Vision API |
| **领域数据** | pyowm | 3.3.0 | OpenWeatherMap API |
| | alpha-vantage | 2.3.1 | Alpha Vantage API |
| | yfinance | 0.2.35 | Yahoo Finance API |
| | openrouteservice | 2.3.3 | OpenRouteService API |
| **异步与数据库** | aiosqlite | 0.19.0 | 异步 SQLite |
| | aiohttp | 3.9.0 | 异步 HTTP |
| **配置与日志** | pydantic | 2.5.0 | 配置验证 |
| | pyyaml | 6.0.1 | YAML 配置解析 |

## 数据流

用户查询首先进入混合路由器，该路由器接收原始查询字符串并执行两阶段分类。第一阶段通过关键词匹配器快速生成路由决策及其置信度得分，若置信度超过0.7阈值，该决策直接作为路由结果进行缓存并传递；若置信度不足，则进入第二阶段由语言模型进行精确分类。路由决策包含任务类型、置信度分数和元数据，据此系统选择对应的执行函数。以研究任务为例，数据流经历四个处理阶段：第一阶段，查询字符串通过语言模型转化为结构化搜索计划，生成3到5个具体搜索查询；第二阶段，搜索查询列表并行提交至搜索API，返回搜索结果集合；第三阶段，顶部搜索结果的URL列表并行传入网页爬虫工具，提取并清理网页正文内容；第四阶段，原始查询、搜索结果和爬取内容的多源数据再次聚合提交至语言模型进行综合分析，生成最终的结构化报告，包含查询内容、搜索计划、信息来源和综合总结。

系统采用全异步处理架构，各阶段的工具调用实现并行执行以优化延迟。数据在各处理阶段经过变换但保持可追踪性：原始字符串逐步转化为列表、字典等结构化格式，最终聚合为包含多个字段的结果对象。所有执行结果经由异步数据库层持久化至SQLite数据库的对话历史表，其中记录包括时间戳、查询内容、执行模式、生成结果和相关元数据。数据持久化后通过服务端事件推送机制以流式传输方式返回给用户，实现实时的交互响应。该数据流设计确保了系统的高效性、可观测性和可靠的数据管理。
